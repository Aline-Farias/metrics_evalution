{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC significa Área Sob Curva ROC.\n",
    "#Isso mede o quão bem o mapa de saliência de uma imagem prevê as fixações humanas na imagem.\n",
    "#A curva ROC é criada varrendo os valores limite\n",
    "#determinado pelo intervalo de valores do mapa de saliência em locais de fixação.\n",
    "#A taxa de verdadeiro positivo (tp) corresponde à proporção dos valores do mapa de saliência acima do limite\n",
    "#em locais de fixação para o número total de locais de fixação.\n",
    "#A taxa de falsos positivos (fp) corresponde à proporção dos valores do mapa de saliência acima do limite\n",
    "#em todos os outros locais para o número total de outros locais possíveis (pixels de imagem não fixados).\n",
    "#AUC=0,5 é o nível de \"chance\".\n",
    "#Um valor de 1 indica uma classificação perfeita.\n",
    "\n",
    "\n",
    "#A métrica AUC-Borji propôs amostrar aleatoriamente negativos de todos os locais de não fixação,\n",
    "#que podem ser considerados como subconjunto da AUC-Judd.\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#from PIL import Image\n",
    "#import numpy\n",
    "\n",
    "q_all = []\n",
    "p_all = []\n",
    "out_all = []\n",
    "\n",
    "print ('Trabalhando nisso...')\n",
    "\n",
    "def normalize(x, method='standard', axis=None):\n",
    "\tx = np.array(x, copy=False)\n",
    "\tif axis is not None:\n",
    "\t\ty = np.rollaxis(x, axis).reshape([x.shape[axis], -1])\n",
    "\t\tshape = np.ones(len(x.shape))\n",
    "\t\tshape[axis] = x.shape[axis]\n",
    "\t\tif method == 'standard':\n",
    "\t\t\tres = (x - np.mean(y, axis=1).reshape(shape)) / np.std(y, axis=1).reshape(shape)\n",
    "\t\telif method == 'range':\n",
    "\t\t\tres = (x - np.min(y, axis=1).reshape(shape)) / (np.max(y, axis=1) - np.min(y, axis=1)).reshape(shape)\n",
    "\t\telif method == 'sum':\n",
    "\t\t\tres = x / np.float_(np.sum(y, axis=1).reshape(shape))\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('method not in {\"standard\", \"range\", \"sum\"}')\n",
    "\telse:\n",
    "\t\tif method == 'standard':\n",
    "\t\t\tres = (x - np.mean(x)) / np.std(x)\n",
    "\t\telif method == 'range':\n",
    "\t\t\tres = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\t\telif method == 'sum':\n",
    "\t\t\tres = x / float(np.sum(x))\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('method not in {\"standard\", \"range\", \"sum\"}')\n",
    "\treturn res\n",
    "\n",
    "def AUC_Borji(saliency_map, fixation_map, n_rep=100, step_size=0.1, rand_sampler=None):\n",
    "    \n",
    "    # saliency_map is the saliency map\n",
    "    # fixation_map is the human fixation map (binary matrix)\n",
    "    \n",
    "\t#Parâmetros\n",
    "\t#----------\n",
    "\t#saliency_map : matriz de valor real\n",
    "\t#fixação_map : matriz binária\n",
    "\t#\tMapa de fixação humana.\n",
    "\t#jitter : booleano, opcional\n",
    "\t#\tSe True (padrão), um pequeno número aleatório seria adicionado a cada pixel do mapa de saliência.\n",
    "\t#\tMapas de saliência de jitter que vêm de modelos de saliência que têm muitos valores zero.\n",
    "\t#\tSe o mapa de saliência for feito com uma gaussiana, ele não precisa ser alterado\n",
    "\t#\tpois os valores variam e não há um grande patch do mesmo valor.\n",
    "\t#\tNa verdade, o jittering quebra a ordenação nos pequenos valores!\n",
    "    #Resultados:\n",
    "\t#-------\n",
    "\t#AUC : float, entre [0,1]\n",
    "                      \n",
    "    \n",
    "\tsaliency_map = np.array(saliency_map, copy=False)\n",
    "\tfixation_map = np.array(fixation_map, copy=False) > 0.5\n",
    "\t# If there are no fixation to predict, return NaN\n",
    "\tif not np.any(fixation_map):\n",
    "\t\tprint('no fixation to predict')\n",
    "\t\treturn np.nan\n",
    "\t# Make the saliency_map the size of the fixation_map\n",
    "\tif saliency_map.shape != fixation_map.shape:\n",
    "\t\tsaliency_map = resize(saliency_map, fixation_map.shape, order=3, mode='constant')\n",
    "\t# Normalize saliency map to have values between [0,1]\n",
    "\tsaliency_map = normalize(saliency_map, method='range')\n",
    "\n",
    "\tS = saliency_map.ravel()\n",
    "\tF = fixation_map.ravel()\n",
    "\tS_fix = S[F] # Saliency map values at fixation locations\n",
    "\tn_fix = len(S_fix)\n",
    "\tn_pixels = len(S)\n",
    "\t# For each fixation, sample n_rep values from anywhere on the saliency map\n",
    "\tif rand_sampler is None:\n",
    "\t\t#r = random.randint(0, n_pixels, [n_fix, n_rep])\n",
    "\t\tr = numpy.random.randint(0, n_pixels, [n_fix, n_rep])\n",
    "\t\tS_rand = S[r] # Saliency map values at random locations (including fixated locations!? underestimated)\n",
    "\telse:\n",
    "\t\tS_rand = rand_sampler(S, F, n_rep, n_fix)\n",
    "        \n",
    "\t# Calculate AUC per random split (set of random locations)\n",
    "\tauc = np.zeros(n_rep) * np.nan\n",
    "\tfor rep in range(n_rep):\n",
    "\t\t#thresholds = np.r_[0:np.max(np.r_[S_fix, S_rand[:,rep]]):step_size][::-1]\n",
    "        \n",
    "\t\tthresholds = np.r_[S_fix, S_rand[:,rep]]   \n",
    "\t\tthresholds = np.max(thresholds)\n",
    "\t\t#print(thresholds)\n",
    "\t\tthresholds = np.r_[0:thresholds:step_size][::-1]       \n",
    "        \n",
    "\t\ttp = np.zeros(len(thresholds)+2)\n",
    "\t\tfp = np.zeros(len(thresholds)+2)\n",
    "\t\ttp[0] = 0; tp[-1] = 1\n",
    "\t\tfp[0] = 0; fp[-1] = 1\n",
    "\t\tfor k, thresh in enumerate(thresholds):\n",
    "\t\t\ttp[k+1] = np.sum(S_fix >= thresh) / float(n_fix)\n",
    "\t\t\tfp[k+1] = np.sum(S_rand[:,rep] >= thresh) / float(n_fix)\n",
    "\t\tauc[rep] = np.trapz(tp, fp)\n",
    "\treturn np.mean(auc) # Average across random splits\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    folder = r'...\\saliency_all' #Diretório que contenha os mapas de saliência e os grounds truth\n",
    "\n",
    "    gt_saliency_folder = folder + '\\salmap' #mapas de saliencia do modelo\n",
    "    gt_fixation_folder = folder + '\\\\fixmap' #mapas de saliencia - ground truth\n",
    "    #print(gt_saliency_folder)\n",
    "     \n",
    "            \n",
    "    for filename_sal in glob.glob(os.path.join(gt_saliency_folder,'*.png')):\n",
    "        #print(filename_sal)\n",
    "        p= plt.imread(filename_sal)\n",
    "        p_all.append(p)\n",
    "    for filename_fix in glob.glob(os.path.join(gt_fixation_folder,'*.jpeg')):\n",
    "        #print(filename_fix)\n",
    "        q= plt.imread(filename_fix)\n",
    "        q_all.append(p)              \n",
    "            \n",
    "    for i in range(0,len(p_all)):\n",
    "        out = AUC_Borji(p_all[i],p_all[i])\n",
    "        out_all.append(out)\n",
    "    soma = sum(out_all)\n",
    "    media = soma/len(p_all)\n",
    "    print (media) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
